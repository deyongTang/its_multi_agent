from collections.abc import AsyncGenerator
from typing import Any
from utils.response_util import ResponseFactory
from schemas.response import ContentKind
from infrastructure.logging.logger import logger

# åªæœ‰è¿™äº›èŠ‚ç‚¹çš„ LLM è¾“å‡ºæ‰é€ä¼ ç»™å‰ç«¯ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
_ANSWER_NODES = {"generate_report", "general_chat", "ask_user"}

async def process_workflow_stream(workflow_stream: AsyncGenerator) -> AsyncGenerator:
    """
    å¤„ç† LangGraph å¼‚æ­¥äº‹ä»¶æµå¹¶è½¬æ¢ä¸ºå‰ç«¯ SSE æ ¼å¼

    Args:
        workflow_stream: LangGraph astream_events ç”Ÿæˆå™¨
    """
    # è¿½è¸ªå½“å‰æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆç”¨äºè¿‡æ»¤ on_chat_model_stream æ¥æºï¼‰
    current_node: str = ""

    async for event in workflow_stream:
        kind = event.get("event")
        name = event.get("name")
        data = event.get("data")

        # 1. å¤„ç†èŠ‚ç‚¹å¼€å§‹/ç»“æŸäº‹ä»¶ (PROCESS ç±»å‹)
        if kind == "on_chain_start" and name == "LangGraph":
             pass # æµç¨‹å¼€å§‹

        # è¿½é—®èŠ‚ç‚¹ç»“æŸæ—¶ï¼Œä» output state å–å‡ºè¿½é—®å†…å®¹å‘ç»™å‰ç«¯
        elif kind == "on_chain_end" and name == "ask_user":
            output = data.get("output", {})
            messages = output.get("messages", [])
            pending_intent = output.get("current_intent", "")
            for msg in messages:
                content = msg.content if hasattr(msg, "content") else str(msg)
                if content:
                    import json as _json
                    packet = ResponseFactory.build_text(content, ContentKind.ANSWER).model_dump()
                    packet["is_ask_user"] = True
                    packet["pending_intent"] = pending_intent
                    yield "data: " + _json.dumps(packet, ensure_ascii=False) + "\n\n"

        elif kind == "on_node_start":
            node_name = name
            current_node = node_name
            # è¿‡æ»¤æ‰å†…éƒ¨èŠ‚ç‚¹åç§°ï¼Œåªå±•ç¤ºæœ‰æ„ä¹‰çš„èŠ‚ç‚¹
            if node_name not in ["__start__", "__end__", "LangGraph"]:
                text = f"è¿›å…¥ç¯èŠ‚: {node_name}"
                yield "data: " + ResponseFactory.build_text(
                    f"ğŸ”„ {text}", ContentKind.PROCESS
                ).model_dump_json() + "\n\n"

        elif kind == "on_node_end":
            current_node = ""

        # 2. å¤„ç†èŠå¤©æ¨¡å‹è¾“å‡º (åŒ…å«æ¨ç†å’Œå›ç­”)
        elif kind == "on_chat_model_stream":
            chunk = data.get("chunk", None)
            if not chunk:
                continue

            # ä»äº‹ä»¶å…ƒæ•°æ®ä¸­è·å–è§¦å‘è¯¥ LLM è°ƒç”¨çš„çˆ¶èŠ‚ç‚¹åç§°
            # astream_events v2 åœ¨ metadata ä¸­æºå¸¦ langgraph_node
            metadata = event.get("metadata", {})
            source_node = metadata.get("langgraph_node", current_node)

            # --- A. æå–æ¨ç†å†…å®¹ (Thinking) ---
            reasoning = None
            if hasattr(chunk, "reasoning_content") and chunk.reasoning_content:
                reasoning = chunk.reasoning_content
            elif hasattr(chunk, "additional_kwargs") and "reasoning_content" in chunk.additional_kwargs:
                reasoning = chunk.additional_kwargs["reasoning_content"]

            if reasoning:
                yield "data: " + ResponseFactory.build_text(
                    reasoning, ContentKind.THINKING
                ).model_dump_json() + "\n\n"

            # --- B. æå–æœ€ç»ˆå›ç­” (Answer) ---
            # åªæœ‰ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹çš„è¾“å‡ºæ‰ä½œä¸º ANSWER é€ä¼ ï¼Œå…¶ä½™èŠ‚ç‚¹çš„ LLM è¾“å‡ºé™é»˜è¿‡æ»¤
            content = chunk.content if hasattr(chunk, "content") else None
            if content and source_node in _ANSWER_NODES:
                yield "data: " + ResponseFactory.build_text(
                    content, ContentKind.ANSWER
                ).model_dump_json() + "\n\n"

        # 3. å¤„ç†å·¥å…·è°ƒç”¨ (PROCESS ç±»å‹)
        elif kind == "on_tool_start":
            tool_name = name
            yield "data: " + ResponseFactory.build_text(
                f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}", ContentKind.PROCESS
            ).model_dump_json() + "\n\n"

        # 4. è‡ªå®šä¹‰äº‹ä»¶ (æ”¯æŒä» Node å†…éƒ¨æ‰‹åŠ¨ yield äº‹ä»¶)
        elif kind == "on_custom_event":
             # é¢„ç•™ç»™æœªæ¥æ‰©å±•ï¼Œä¾‹å¦‚æ£€ç´¢åˆ°çš„æ–‡æ¡£è¯¦æƒ…
             pass

    # 5. å‘é€ç»“æŸä¿¡å·
    yield "data: " + ResponseFactory.build_finish().model_dump_json() + "\n\n"