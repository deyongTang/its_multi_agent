from collections.abc import AsyncGenerator
from typing import Any
from utils.response_util import ResponseFactory
from schemas.response import ContentKind
from infrastructure.logging.logger import logger

async def process_workflow_stream(workflow_stream: AsyncGenerator) -> AsyncGenerator:
    """
    å¤„ç† LangGraph å¼‚æ­¥äº‹ä»¶æµå¹¶è½¬æ¢ä¸ºå‰ç«¯ SSE æ ¼å¼
    
    Args:
        workflow_stream: LangGraph astream_events ç”Ÿæˆå™¨
    """
    
    async for event in workflow_stream:
        kind = event.get("event")
        name = event.get("name")
        data = event.get("data")
        
        # 1. å¤„ç†èŠ‚ç‚¹å¼€å§‹/ç»“æŸäº‹ä»¶ (PROCESS ç±»å‹)
        if kind == "on_chain_start" and name == "LangGraph":
             pass # æµç¨‹å¼€å§‹
             
        elif kind == "on_node_start":
            node_name = name
            # è¿‡æ»¤æ‰å†…éƒ¨èŠ‚ç‚¹åç§°ï¼Œåªå±•ç¤ºæœ‰æ„ä¹‰çš„èŠ‚ç‚¹
            if node_name not in ["__start__", "__end__", "LangGraph"]:
                text = f"è¿›å…¥ç¯èŠ‚: {node_name}"
                yield "data: " + ResponseFactory.build_text(
                    f"ğŸ”„ {text}", ContentKind.PROCESS
                ).model_dump_json() + "\n\n"

        # 2. å¤„ç†èŠå¤©æ¨¡å‹è¾“å‡º (åŒ…å«æ¨ç†å’Œå›ç­”)
        elif kind == "on_chat_model_stream":
            chunk = data.get("chunk", None)
            if not chunk:
                continue
                
            # --- A. æå–æ¨ç†å†…å®¹ (Thinking) ---
            # é€‚é… OpenAI å…¼å®¹æ¥å£çš„ reasoning_content
            # DeepSeek R1 ç­‰æ¨¡å‹é€šå¸¸æŠŠæ¨ç†æ”¾åœ¨è¿™é‡Œ
            reasoning = None
            
            # å°è¯•ä»æ ‡å‡† delta ä¸­è·å– (v1)
            if hasattr(chunk, "reasoning_content") and chunk.reasoning_content:
                reasoning = chunk.reasoning_content
            # å°è¯•ä» additional_kwargs ä¸­è·å– (v2/OneAPI)
            elif hasattr(chunk, "additional_kwargs") and "reasoning_content" in chunk.additional_kwargs:
                reasoning = chunk.additional_kwargs["reasoning_content"]
            # å°è¯•ä» message_content çš„ token çº§å±æ€§è·å– (LangChain Specific)
            elif hasattr(chunk, "content") and isinstance(chunk.content, str) and chunk.content.startswith("<thinking>"):
                # å¦‚æœæ¨¡å‹ç›´æ¥åå‡º XML æ ‡ç­¾ï¼Œéœ€è¦è‡ªå·±è§£æï¼ˆæš‚ä¸å®ç°å¤æ‚è§£æï¼Œå‡è®¾ API å·²ç»ç»“æ„åŒ–ï¼‰
                pass
            
            if reasoning:
                yield "data: " + ResponseFactory.build_text(
                    reasoning, ContentKind.THINKING
                ).model_dump_json() + "\n\n"

            # --- B. æå–æœ€ç»ˆå›ç­” (Answer) ---
            content = chunk.content if hasattr(chunk, "content") else None
            if content:
                yield "data: " + ResponseFactory.build_text(
                    content, ContentKind.ANSWER
                ).model_dump_json() + "\n\n"

        # 3. å¤„ç†å·¥å…·è°ƒç”¨ (PROCESS ç±»å‹)
        elif kind == "on_tool_start":
            tool_name = name
            tool_input = data.get("input", "")
            text = f"è°ƒç”¨å·¥å…·: {tool_name}"
            yield "data: " + ResponseFactory.build_text(
                f"ğŸ”§ {text}", ContentKind.PROCESS
            ).model_dump_json() + "\n\n"
            
        # 4. è‡ªå®šä¹‰äº‹ä»¶ (æ”¯æŒä» Node å†…éƒ¨æ‰‹åŠ¨ yield äº‹ä»¶)
        elif kind == "on_custom_event":
             # é¢„ç•™ç»™æœªæ¥æ‰©å±•ï¼Œä¾‹å¦‚æ£€ç´¢åˆ°çš„æ–‡æ¡£è¯¦æƒ…
             pass

    # 5. å‘é€ç»“æŸä¿¡å·
    yield "data: " + ResponseFactory.build_finish().model_dump_json() + "\n\n"