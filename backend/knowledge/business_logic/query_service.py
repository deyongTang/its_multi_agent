from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from typing import List
from config.settings import settings
import re

def clean_markdown_images(text: str) -> str:
    """å°† [æè¿°](url) æ›¿æ¢ä¸ºçº¯ urlï¼Œæ¯å¼ å›¾å•ç‹¬ä¸€è¡Œ"""
    pattern = r'!\$$[^$$]*\]\((https?://[^\s\)]+)\)'
    def replace_func(match):
        url = match.group(1)
        return f"\n{url}\n"
    cleaned = re.sub(pattern, replace_func, text)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    return cleaned.strip()

class QueryService:
    def __init__(self):
        # æ³¨æ„ï¼šapi_key å’Œ base_url å·²é€šè¿‡ main.py çš„ setup_environment() è®¾ç½®åˆ°ç¯å¢ƒå˜é‡
        # ChatOpenAI ä¼šè‡ªåŠ¨ä» OPENAI_API_KEY å’Œ OPENAI_BASE_URL ç¯å¢ƒå˜é‡è¯»å–
        self.llm = ChatOpenAI(
            model=settings.MODEL,
            temperature=0,
            timeout=60,  # è®¾ç½®60ç§’è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
            max_retries=2  # æœ€å¤šé‡è¯•2æ¬¡
        )

    def rewrite_query(self, question: str) -> str:
        """
        åˆ©ç”¨ LLM å¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œé‡å†™ï¼Œä½¿å…¶æ›´é€‚åˆçŸ¥è¯†åº“æ£€ç´¢ã€‚
        ä¾‹å¦‚ï¼šå»é™¤å£è¯­åŒ–è¯æ±‡ã€è¡¥å……ç¼ºå¤±çš„ä¸»è¯­ã€è§„èŒƒåŒ–æœ¯è¯­ã€‚
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœç´¢æŸ¥è¯¢ä¼˜åŒ–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è¾“å…¥é‡å†™ä¸ºä¸€ä¸ªæ›´ç²¾å‡†ã€æ›´é€‚åˆä» IT çŸ¥è¯†åº“ä¸­æ£€ç´¢æ–‡æ¡£çš„æŸ¥è¯¢è¯­å¥ã€‚

        è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
        1. å»é™¤æ— æ„ä¹‰çš„è¯­æ°”è¯ï¼ˆå¦‚â€œå•Šâ€ã€â€œå‘¢â€ã€â€œæ€ä¹ˆåŠâ€ï¼‰ã€‚
        2. è¡¥å……å¯èƒ½çš„ç¼ºå¤±ä¿¡æ¯ï¼ˆæ ¹æ®å¸¸è¯†æ¨æ–­ï¼‰ã€‚
        3. å°†å£è¯­åŒ–æè¿°è½¬æ¢ä¸ºä¸“ä¸šæœ¯è¯­ï¼ˆä¾‹å¦‚â€œè¿ä¸ä¸Šç½‘â€ -> â€œç½‘ç»œè¿æ¥å¤±è´¥â€ï¼‰ã€‚
        4. ä¿æŒç®€æ´ï¼Œç›´æ¥è¾“å‡ºé‡å†™åçš„æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–æ–‡å­—ã€‚

        ç”¨æˆ·è¾“å…¥: {question}
        é‡å†™åçš„æŸ¥è¯¢:
        """
        try:
            from langchain_core.messages import HumanMessage
            # è°ƒç”¨ LLM ç”Ÿæˆé‡å†™åçš„æŸ¥è¯¢
            response = self.llm.invoke([HumanMessage(content=prompt)])
            rewritten_query = response.content.strip()
            
            # ç®€å•çš„åå¤„ç†ï¼Œå»æ‰å¯èƒ½åŒ…å«çš„å¼•å·
            rewritten_query = rewritten_query.replace('"', '').replace("'", "")
            
            return rewritten_query
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢é‡å†™å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹é—®é¢˜: {e}")
            return question

    def generate_answer(self, question: str, context_docs: List[Document]) -> str:
        """ç”Ÿæˆå›ç­”"""
        if not context_docs:
            return "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œè¯·ä¸Šä¼ ç›¸å…³æ–‡æ¡£åå†æŸ¥è¯¢ã€‚"

        context_text = "\n\n".join([f"èµ„æ–™{i + 1}ï¼š{doc.page_content}" for i, doc in enumerate(context_docs)])
        
        prompt = f"""
       è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸èƒ½åŸºäºèµ„æ–™ä¸­æœªæåŠçš„ä¿¡æ¯ã€‚

       ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘
        - èµ„æ–™ä¸­çš„å›¾ç‰‡é“¾æ¥å¿…é¡»ä¿ç•™ï¼Œä½†**ä¸è¦ä½¿ç”¨ Markdown å›¾ç‰‡è¯­æ³•ï¼ˆå¦‚ [æè¿°](é“¾æ¥)ï¼‰**ã€‚
        - è¯·ç›´æ¥å†™å‡º**å®Œæ•´çš„å›¾ç‰‡ URL**ï¼ˆä¾‹å¦‚ï¼šhttps://example.com/image.pngï¼‰ï¼Œæ¯å¼ å›¾å ä¸€è¡Œã€‚
        - å›ç­”åº”ç®€æ´ã€æ­¥éª¤æ¸…æ™°ï¼Œé¿å…å†—ä½™ä¿¡æ¯ã€‚
        - ä¸è¦æåŠå…·ä½“è®¾å¤‡å‹å·ã€å“ç‰Œæˆ–è½¯ä»¶ç‰ˆæœ¬ï¼ˆå¦‚â€œè”æƒ³â€ã€â€œUltraISOâ€ç­‰ï¼‰ï¼Œé™¤éé—®é¢˜æ˜ç¡®è¦æ±‚ã€‚
        - å¦‚æœå½“å‰é—®é¢˜å’Œèµ„æ–™ä¸­çš„ä¿¡æ¯ä¸ç›¸å…³ï¼Œç›´æ¥å›å¤â€œèµ„æ–™ä¸­æœªæåŠç›¸å…³ä¿¡æ¯â€ã€‚
        
        èµ„æ–™ï¼š```
        {context_text}
        ```
        
        ç”¨æˆ·é—®é¢˜ï¼š```
        {question}
        ```

        å›ç­”ï¼š
        """
        
        try:
            # ä½¿ç”¨æ¶ˆæ¯æ ¼å¼è°ƒç”¨ LLMï¼ˆå…¼å®¹é˜¿é‡Œç™¾ç‚¼ç­‰ APIï¼‰
            from langchain_core.messages import HumanMessage

            messages = [HumanMessage(content=prompt)]
            response = self.llm.invoke(messages)
            answer = response.content
            cleaned_answer = clean_markdown_images(answer)
            return cleaned_answer
        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚"

    def generate_answer_stream(self, question: str, context_docs: List[Document]):
        """
        æµå¼ç”Ÿæˆå›ç­”ï¼ˆGeneratorï¼‰

        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_docs: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£

        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        # å¯¼å…¥æ—¥å¿—æ¨¡å—
        try:
            from infrastructure.logger import logger
        except ImportError:
            logger = None

        if not context_docs:
            yield "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œè¯·ä¸Šä¼ ç›¸å…³æ–‡æ¡£åå†æŸ¥è¯¢ã€‚"
            return

        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä¸ generate_answer ä¿æŒä¸€è‡´ï¼‰
        context_text = "\n\n".join([f"èµ„æ–™{i + 1}ï¼š{doc.page_content}" for i, doc in enumerate(context_docs)])

        # è®°å½•ä¸Šä¸‹æ–‡é•¿åº¦
        if logger:
            logger.info(f"ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: {len(context_text)} å­—ç¬¦ | æ–‡æ¡£æ•°: {len(context_docs)}")

        prompt = f"""
       è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä¸èƒ½åŸºäºèµ„æ–™ä¸­æœªæåŠçš„ä¿¡æ¯ã€‚

       ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘
        - èµ„æ–™ä¸­çš„å›¾ç‰‡é“¾æ¥å¿…é¡»ä¿ç•™ï¼Œä½†**ä¸è¦ä½¿ç”¨ Markdown å›¾ç‰‡è¯­æ³•ï¼ˆå¦‚ [æè¿°](é“¾æ¥)ï¼‰**ã€‚
        - è¯·ç›´æ¥å†™å‡º**å®Œæ•´çš„å›¾ç‰‡ URL**ï¼ˆä¾‹å¦‚ï¼šhttps://example.com/image.pngï¼‰ï¼Œæ¯å¼ å›¾å ä¸€è¡Œã€‚
        - å›ç­”åº”ç®€æ´ã€æ­¥éª¤æ¸…æ™°ï¼Œé¿å…å†—ä½™ä¿¡æ¯ã€‚
        - ä¸è¦æåŠå…·ä½“è®¾å¤‡å‹å·ã€å“ç‰Œæˆ–è½¯ä»¶ç‰ˆæœ¬ï¼ˆå¦‚"è”æƒ³"ã€"UltraISO"ç­‰ï¼‰ï¼Œé™¤éé—®é¢˜æ˜ç¡®è¦æ±‚ã€‚
        - å¦‚æœå½“å‰é—®é¢˜å’Œèµ„æ–™ä¸­çš„ä¿¡æ¯ä¸ç›¸å…³ï¼Œç›´æ¥å›å¤"èµ„æ–™ä¸­æœªæåŠç›¸å…³ä¿¡æ¯"ã€‚

        èµ„æ–™ï¼š```
        {context_text}
        ```

        ç”¨æˆ·é—®é¢˜ï¼š```
        {question}
        ```

        å›ç­”ï¼š
        """

        try:
            from langchain_core.messages import HumanMessage
            import time
            import os

            messages = [HumanMessage(content=prompt)]

            # è®°å½•å¼€å§‹æ—¶é—´å’Œç¯å¢ƒå˜é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            start_time = time.time()
            if logger:
                logger.info("ğŸš€ å¼€å§‹æµå¼ç”Ÿæˆç­”æ¡ˆ")
                logger.debug(f"ğŸ”§ APIé…ç½® | BASE_URL: {os.environ.get('OPENAI_BASE_URL', 'NOT_SET')} | MODEL: {settings.MODEL}")

            # ä½¿ç”¨ stream() æ–¹æ³•è¿›è¡Œæµå¼ç”Ÿæˆ
            chunk_count = 0
            total_chars = 0

            if logger:
                logger.info("ğŸ“¡ æ­£åœ¨è°ƒç”¨ LLM stream API...")

            for chunk in self.llm.stream(messages):
                if chunk.content:
                    chunk_count += 1
                    total_chars += len(chunk.content)

                    # æ¯æ”¶åˆ°ç¬¬ä¸€ä¸ªchunkæ—¶è®°å½•æ—¥å¿—
                    if chunk_count == 1 and logger:
                        logger.info("âœ… å·²æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”å—")

                    yield chunk.content

            # è®°å½•ç»“æŸæ—¶é—´å’Œç»Ÿè®¡ä¿¡æ¯
            elapsed_time = time.time() - start_time
            if logger:
                logger.info(f"âœ… æµå¼ç”Ÿæˆå®Œæˆ | è€—æ—¶: {elapsed_time:.2f}ç§’ | ç”Ÿæˆå­—ç¬¦æ•°: {total_chars} | åˆ†å—æ•°: {chunk_count}")

        except Exception as e:
            if logger:
                logger.error(f"âŒ LLMæµå¼è°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}")
                # è®°å½•å®Œæ•´çš„å¼‚å¸¸å †æ ˆ
                import traceback
                logger.error(f"ğŸ“‹ å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            else:
                print(f"LLMæµå¼è°ƒç”¨å¤±è´¥: {e}")
            yield "æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ã€‚"