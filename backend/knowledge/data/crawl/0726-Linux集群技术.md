# 知识库 726

## 标题
Linux集群技术

## 分类
主类别: 操作系统故障
子类别: 非Windows系统支持

## 关键词
Linux, 集群, 技术, 负载能力

## 元信息
创建时间:2024-12-15|版本:1.0

## 解决方案
       目前，越来越多的网站采用Linux操作系统，提供邮件、Web、文件存储、[数据库](/detail/kd_17734.html)等服务。 也有非常多的公司在企业内部网中利用Linux[服务器](/detail/kd_17589.html)提供这些服务。随着人们对Linux服务器依赖的加深，对其可靠性、负载能力和计算能力也倍加关注。Linux集群技术应运而生，可以以低廉的成本，很好地满足人们的这些需要。 

　　Linux竞争力很强的原因之一，是它可以运行于极为普及的PC机上，不需要购买昂贵的专用[硬件](/detail/kd_17962.html)设备。在几台运行Linux的PC机上，只要加入相应的集群[软件](/detail/kd_17963.html)，就可以组成具有超强可靠性、负载能力和计算能力的Linux集群。集群中的每台服务器称为一个节点。 

　　按照侧重点的不同，可以把Linux集群分为三类。一类是高可用性集群，运行于两个或多个节点上，目的是在系统出现某些故障的情况下，仍能继续对外提供服务。高可用性集群的设计思想就是要最大限度地减少服务中断时间。这类集群中比较著名的有Turbo[linux](/detail/kd_17392.html) TurboHA、Heartbeat、Kimberlite等。第二类是[负载均衡](/detail/kd_17539.html)集群，目的是提供和节点个数成正比的负载能力，这种集群很适合提供大访问量的Web服务。负载均衡集群往往也具有一定的高可用性特点。Turbolinux Cluster Server、Linux Virtual Server都属于负载均衡集群。另一类是超级计算集群，按照计算关联程度的不同，又可以分为两种。一种是任务片方式，要把计算任务分成任务片，再把任务片分配给各节点，在各节点上分别计算后再把结果汇总，生成最终计算结果。另一种是并行计算方式，节点之间在计算过程中大量地交换数据，可以进行具有强耦合关系的计算。这两种超级计算集群分别适用于不同类型的数据处理工作。有了超级计算集群软件，企业利用若干台PC机就可以完成通常只有超级计算机才能完成的计算任务。这类软件有Turbolinux EnFusion、SCore等。 

　　高可用性集群与负载均衡集群的工作原理不同，适用于不同类型的服务。通常，负载均衡集群适用于提供静态数据的服务，如HTTP服务；而高可用性集群既适用于提供静态数据的服务，如HTTP服务，又适用于提供动态数据的服务，如数据库等。高可用性集群之所以能适用于提供动态数据的服务，是由于节点[共享](/detail/kd_17685.html)同一存储介质，如[RAID](/detail/kd_17695.html)Box。也就是说，在高可用性集群内，每种服务的用户数据只有一份，存储在共用存储设备上，在任一时刻只有一个节点能读写这份数据。 

　　以Turbolinux TurboHA为例，集群中有两个节点A和B，设这个集群只提供Oracle服务，用户数据存放于共用存储设备的分区/dev/sdb3上。在正常状态下，节点A提供Oracle数据库服务，分区/dev/sdb3被节点A加载在/mnt/oracle上。当系统出现某种故障并被TurboHA软件检测到时，TurboHA会将Oracle服务停止，并把分区/dev/sdb3卸载。之后，节点B上的TurboHA软件将在节点B上加载该分区，并[启动](/detail/kd_17514.html)Oracle服务。对于Oracle服务有一个虚拟的[IP](/detail/kd_17443.html)地址，当Oracle服务从节点A切换到节点B上时，虚拟的IP地址也会随之[绑定](/detail/kd_18083.html)到节点B上，因此用户仍可访问此服务。 

　　由以上分析可以看出，高可用性集群对一种服务而言不具有负载均衡功能，它可以提高整个系统的可靠性，但不能增加负载的能力。当然，高可用性集群可以运行多种服务，并适当分配在不同节点上，比如节点A提供Oracle服务，同时节点B提供Sybase服务，这也可以看成是某种意义上的负载均衡，不过这是对多种服务的分配而言。 

　　负载均衡集群适用于提供相对静态的数据的服务，比如HTTP服务。因为通常负载均衡集群的各节点间通常没有共用的存储介质，用户数据被复制成多份，存放于每一个提供该项服务的节点上。 

下面以Turbolinux Cluster Server为例简要介绍一下负载均衡集群的工作机制。在集群中有一个主控节点，称为高级流量管理器（ATM）。假设这一集群仅被用来提供一项HTTP服务，其余各节点均被设定为HTTP的服务节点。用户对于页面的请求全部发送到ATM上，因为ATM上绑定了这项服务对外的IP地址。ATM把接受到的请求再平均发送到各服务节点上，服务节点接收到请求之后，直接把相应的Web页面发送给用户。这样一来，假如在1秒内有1000个HTTP页面请求，而集群中有10个服务节点，则每个节点将处理100个请求。这样，在外界看来，好象有一台10倍速度的高速计算机在处理用户的访问。这也就是真正意义上的负载均衡。 

　　但是ATM要处理所有1000个页面请求，它会不会成为集群处理速度的瓶颈呢？由于对于页面的请求的数据量相对较少，返回页面内容的数据量相对较大，因此这种方式还是很有效率的。ATM发生故障，也不会导致整个系统无法工作。Turbolinux Cluster Server可以设置一台或多台计算机为后备ATM节点，当主ATM节点故障时，在后备ATM中会产生出一个新的主ATM，接替它的工作。可以看出，这种负载均衡集群也具有一定的高可用性。 

　　HTTP页面相对是静态的，但有时也需要改动。Turbolinux Cluster Server提供了数据同步工具，可以很方便的把对页面的改动同步到所有提供该项服务的节点上。 

　　下面介绍一下对于高可用性集群与负载均衡集群的组合使用。如果用户有一个由两个节点组成的最小集群，是否可以同时获得高可用性集群和负载均衡集群的效益呢？答案是肯定的。由于高可用性集群适用于提供动态数据的服务，而负载均衡集群适用于提供静态数据的服务，所以我们不妨假设要同时提供Oracle和HTTP服务。用户要在节点A和B上安装TurbolinuxTurboHA和TurbolinuxClusterServer软件。把节点A作为Oracle正常工作的节点，节点B作为Oracle服务的后备节点，这是对TurboHA软件而言。对于ClusterServer软件而言，要设置节点B为主ATM节点，节点A为后备ATM节点，而节点A和节点B同时又都是HTTP的服务节点。 

　　这样一来，节点A和节点B都是身兼两职，而用户同时得到了一个具有高可用性的Oracle服务和一个具有负载均衡功能的HTTP服务。即使有一个节点发生故障，Oracle服务和HTTP服务都不会因此而中断。 

　　但对于同一种服务，是不能同时获得高可用性与负载均衡能力的。对一种服务，要么是只有一份数据，放在共用存储设备上，一次被一个节点访问，获得高可用性；要么是把数据复制为多份，存储于每个节点的本地[硬盘](/detail/kd_17342.html)上，用户的请求同时发送到多个节点上，获得负载均衡能力。 

　　对于高可用性集群，由于它在设计时的目的就是为了最大可能地减少服务中断时间，因此服务的切换受到很大的关注。当一个节点上的服务故障时，会被很快地检测到并被切换到其他节点上。但在切换时，不能忽略对数据完整性的保护。   
在什么情况下数据完整性会被破坏呢？由于高可用性集群中至少有两个节点，连接在一个共用的存储设备上，对于非裸分区而言，如果被两个节点同时读写，就会造成文件系统被破坏。因此就需要利用I/O屏障来防止这一事件的发生。 

　　I/O屏障的目的是为了保证故障节点不能再继续读写某一服务的共用分区，实现的方式有多种。Kimberlite使用硬件开关来实现，当一个节点发生故障时，另一节点如果能侦测到，就会通过串行口发出命令，控制连接在故障节点电源上的硬件开关，通过暂时断电，而后又上电的方式使得故障节点被[重启](/detail/kd_17977.html)动。 

　　I/O屏障有多种形式。对于支持[SCSI](/detail/kd_17380.html) Reserve/Release命令的存储设备，也可以用SG命令实现I/O屏障。正常节点应使用SCSI Reserve命令“锁住”共用存储设备，保证其不被故障节点读写。如果故障节点上的集群软件仍在运行，如发现共用存储设备已被对方锁住，就应把自己重启动，以恢复正常工作状态。 

　    以上介绍了Linux集群技术的基本原理，也介绍了几种著名的软件。总之，Linux集群技术最大的发挥了

        PC机和网络的优势，可以带来可观的性能，是一种大有前途的技术。

<!-- 文档主题：Linux集群技术 (知识库库编号: 726) -->